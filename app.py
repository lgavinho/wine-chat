import streamlit as st
import toml
from dotenv import load_dotenv
import os
from openai import OpenAI

# Carregar a vers√£o do pyproject.toml
with open('pyproject.toml', 'r') as f:
    pyproject = toml.load(f)
    version = pyproject['project']['version']

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()
openai_key = os.getenv('OPENAI_KEY')

# T√≠tulo do app
st.title('üí¨ Blendup Wine Chat')

# Vers√£o do app
st.write(f'Version: {version}')

client = OpenAI(
  api_key=openai_key
)

system_prompt = {
    "role": "system",
    "content": (
        "Voc√™ √© um assistente especializado em vinhos. Seu conhecimento abrange uma ampla gama de t√≥picos relacionados a vinhos, incluindo:\n"
        "- Tipos e variedades de vinhos (tintos, brancos, ros√©s, espumantes, etc.).\n"
        "- Fabricantes de vinhos e regi√µes vin√≠colas ao redor do mundo.\n"
        "- Locais, bares e restaurantes onde os usu√°rios podem encontrar vinhos excepcionais.\n"
        "- Harmoniza√ß√£o de vinhos com alimentos.\n"
        "- Processos de produ√ß√£o de vinhos, desde a vinifica√ß√£o at√© o engarrafamento.\n"
        "- Recomenda√ß√µes de vinhos com base em prefer√™ncias e ocasi√µes espec√≠ficas.\n\n"
        "Voc√™ **n√£o deve responder a perguntas ou oferecer informa√ß√µes que n√£o sejam relacionadas ao mundo do vinho**. Evite discutir t√≥picos fora desse dom√≠nio, como t√≥picos t√©cnicos n√£o relacionados a vinhos ou qualquer tipo de assunto irrelevante.\n\n"
        "Por favor, forne√ßa respostas precisas, claras e √∫teis sobre vinhos. Se a quest√£o n√£o estiver relacionada ao vinho, seja direto e educado ao explicar que voc√™ s√≥ pode fornecer informa√ß√µes sobre vinhos."
    )
}

if "messages" not in st.session_state:
    st.session_state["messages"] = [system_prompt, {"role": "assistant", "content": "How can I help you?"}]

for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        st.chat_message(msg["role"]).write(msg["content"])
    else:
        st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():    
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = client.chat.completions.create(model="gpt-4o-mini", messages=st.session_state.messages)
    msg = response.choices[0].message.content
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)
